{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "The notes on linear algebra contain an example on singular value decomposition. See the slide entitled, 'Modelling \"Person\" -- SVD'. Write python code to reproduce the calculations related to the calculation of the prediction of Alice's rating of the movie \"Eat Pray Love\". The answer to be reproduced is shown on the slide entitled 'Example for SVD-based recommendation'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction is: 5.35\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = [\n",
    "    [3, 1, 2, 3],\n",
    "    [4, 3, 4, 3],\n",
    "    [3, 2, 1, 5],\n",
    "    [1, 6, 5, 2]\n",
    "]\n",
    "\n",
    "u, s, v = np.linalg.svd(A)\n",
    "\n",
    "u = [i[:2] for i in u]\n",
    "\n",
    "s = np.multiply(s, np.identity(4))\n",
    "\n",
    "s = [i[:2] for i in s]\n",
    "v = [i[:2] for i in v.T]\n",
    "\n",
    "# switched u and v\n",
    "sv = np.dot(s[:2], u[3])\n",
    "usv = np.dot(v[0], sv)\n",
    "\n",
    "prediction = 4 + usv\n",
    "print 'prediction is: %.2f' % prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question 2\n",
    "\n",
    "Compute the SVD for the matrix below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([\n",
    "    [1,2,3],\n",
    "    [2,3,4],\n",
    "    [4,5,6],\n",
    "    [1,1,1]\n",
    "])\n",
    "\n",
    "u,s,v = np.linalg.svd(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "The left figure above represents the surface. The right figure represents 50 of the singular values. Compute the best rank(2) matrix, A2, approximation to the matrix A. What is ||A - A2||?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "e = lambda i: -0.7 + 0.001 * (i - 1)\n",
    "r = range(1, 1402)\n",
    "k = 2 # finding best rank2\n",
    "\n",
    "# generate A\n",
    "A = [[math.sqrt(1 - e(i) ** 2 - e(j) ** 2) for j in r] for i in r]\n",
    "\n",
    "u, s, vt = np.linalg.svd(A)\n",
    "\n",
    "vtk = vt[:k] # first two rows of v transpose (k x n)\n",
    "\n",
    "# for uk we get each column as a row with this, so we transpose it\n",
    "uk  = np.array([u[:, i] for i in range(0, k)]).T # first k columns of u (n x k)\n",
    "sk  = np.multiply(np.identity(k), s[:k]) # first k singular values (k x k)\n",
    "\n",
    "Ak = np.dot(uk, np.dot(sk, vtk)) # (n x k) x ((k x k) x (k x n)) = (n x n)\n",
    "\n",
    "assert np.shape(Ak) == (len(r), len(r))\n",
    "assert np.linalg.matrix_rank(Ak) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can determine the euclidean norm of A - A_(k=2) by looking at the third largest singular value of S from the singular value decomposition of A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.testing import assert_almost_equal\n",
    "\n",
    "r = range(0, 1401)\n",
    "\n",
    "t = lambda i, j: (A[i][j] - Ak[i][j]) ** 2\n",
    "\n",
    "norm = math.sqrt(sum([sum([t(i, j) for j in r]) for i in r]))\n",
    "assert_almost_equal(np.linalg.norm(A - Ak), norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "Using the matrix A from Question 2, and let b = [1,1,1,1]T, using the gradient descent method, determine the least squares solution of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.14705882  0.05882353  0.26470588]\n"
     ]
    }
   ],
   "source": [
    "tolerance = 0.01\n",
    "stepsize = 0.01 # E\n",
    "\n",
    "A = np.array([\n",
    "    [1,2,4,1],\n",
    "    [2,3,5,1],\n",
    "    [3,4,6,1]\n",
    "]).T\n",
    "\n",
    "b = np.array([1,1,1,1])\n",
    "\n",
    "\n",
    "x, res, rank, sv = np.linalg.lstsq(A,b)\n",
    "\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" cellpadding=\"3\" cellspacing=\"0\"  style=\"border:black; border-collapse:collapse;\"><tr><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">Step&nbsp;Size</td><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">Iterations</td><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">x</td></tr><tr><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.0100</td><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">487</td><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">[-0.192869&nbsp;&nbsp;&nbsp;&nbsp;0.17120088&nbsp;&nbsp;0.20239903]</td></tr><tr><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.0500</td><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">435</td><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">[-inf&nbsp;-inf&nbsp;&nbsp;nan]</td></tr><tr><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.1000</td><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">295</td><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">[&nbsp;nan&nbsp;&nbsp;nan&nbsp;&nbsp;nan]</td></tr><tr><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.1500</td><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">250</td><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">[&nbsp;nan&nbsp;&nbsp;nan&nbsp;&nbsp;nan]</td></tr><tr><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.2000</td><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">226</td><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">[&nbsp;nan&nbsp;&nbsp;nan&nbsp;&nbsp;nan]</td></tr><tr><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.2500</td><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">211</td><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">[&nbsp;nan&nbsp;&nbsp;nan&nbsp;&nbsp;nan]</td></tr><tr><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.5000</td><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">175</td><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">[&nbsp;nan&nbsp;&nbsp;nan&nbsp;&nbsp;nan]</td></tr></table>"
      ],
      "text/plain": [
       "<ipy_table.ipy_table.IpyTable at 0x1077f5810>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from ipy_table import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "table = [[\"Step Size\", \"Iterations\", \"x\"]]\n",
    "tolerance = 0.01\n",
    "\n",
    "A = np.array([\n",
    "    [1,2,3],\n",
    "    [2,3,4],\n",
    "    [4,5,6],\n",
    "    [1,1,1]\n",
    "])\n",
    "\n",
    "b = np.array([1,1,1,1])\n",
    "\n",
    "r = {}\n",
    "\n",
    "# t = lambda x: np.dot(A.T, np.dot(A, x)) - np.dot(A.T, b)\n",
    "\n",
    "def t (x):\n",
    "    try:\n",
    "        return np.dot(A.T, np.dot(A, x)) - np.dot(A.T, b)\n",
    "    except RuntimeWarning:\n",
    "        return x\n",
    "ix = x = np.random.rand(3)\n",
    "\n",
    "for stepsize in [0.01,0.05,0.1,0.15,0.2,0.25,0.5]:\n",
    "    x = ix\n",
    "    iterations = 0\n",
    "    while np.linalg.norm(t(x), 2) > tolerance:\n",
    "        try:\n",
    "            x = x - np.dot(stepsize, t(x))\n",
    "        except RuntimeWarning:\n",
    "            break;\n",
    "        iterations += 1\n",
    "    table.append([stepsize, iterations, x])\n",
    "make_table(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "From the properties of an svd, the null space of an m * n matrix A is spanned by the last (n-r) columns of V (where r is rank(A))\n",
    "\n",
    "<img src='./rules.png'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two l.i vectors of null(A)\n",
      "\n",
      "[-0.04453418  0.85004094  0.44341588 -0.28076586]\n",
      "[ 0.8290113  -0.2330726   0.24969281 -0.44279897]\n",
      "if columns are l.i in R3, col(A) will have 4 terms\n",
      "the column space of A is spanned by the first r columns of U\n",
      "since r is only 2, the above columns are not li in R3\n",
      "[ 0.81049889  0.31970025 -0.49079864]\n",
      "[ 0.0987837   0.75130448  0.65252078]\n",
      "the row space of A is spanned by the first R columns of V\n",
      "[ 0.55385992  0.38616463 -0.24385636  0.69616819]\n",
      "[-0.0632152  -0.27200083  0.82557249  0.49035646]\n",
      "again, only 2 rows needed to span row space\n",
      "its not LI in R4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = [\n",
    "    [3, 2, -1, 4],\n",
    "    [1, 0, 2, 3],\n",
    "    [-2, -2, 3, -1]\n",
    "]\n",
    "\n",
    "u, s, vt = np.linalg.svd(A)\n",
    "\n",
    "r = np.linalg.matrix_rank(A)\n",
    "m, n = np.shape(A)\n",
    "\n",
    "V = vt.T\n",
    "\n",
    "columns = [V[:,(n - 1) - i] for i in range(0, r)]\n",
    "print 'two l.i vectors of null(A)\\n'\n",
    "print \"\\n\".join([str(i) for i in columns])\n",
    "\n",
    "print 'if columns are l.i in R3, col(A) will have 4 terms'\n",
    "\n",
    "print 'the column space of A is spanned by the first r columns of U'\n",
    "print 'since r is only 2, the above columns are not li in R3'\n",
    "\n",
    "columns = [u[:, i] for i in range(0, r)]\n",
    "print \"\\n\".join([str(i) for i in columns])\n",
    "\n",
    "print 'the row space of A is spanned by the first R columns of V'\n",
    "\n",
    "columns = [V[:, i] for i in range(0, r)]\n",
    "print \"\\n\".join([str(i) for i in columns])\n",
    "print 'again, only 2 rows needed to span row space'\n",
    "print 'its not LI in R4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "\n",
    "In a certain place it rains on *one third of the days.* The local evening newspaper attempts to predict whether or not it will rain the following day. Three quarters of rainy days and three fifths of dry days are correctly predicted by the previous evening's paper. Given that this evening's paper predicts rain, what is the probability that it will actually rain tomorrow?\n",
    "\n",
    "<img src='./bayes.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll let `A` be the probability it rains, which is one out of three. While `Pr(B|A)` being the probability of the correction being accurately predicted from the previous night's paper. We solve for `Pr(A|B)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48\n"
     ]
    }
   ],
   "source": [
    "P_A = 1.0 / 3.0 # chance it rains\n",
    "P_BA = 3.0 / 4.0 # chance that rains predicted given it rained\n",
    "P_DRY = 3.0 / 5.0 # chance that it is predicted to be dry\n",
    "\n",
    "\"\"\"\n",
    " P_B being\n",
    "  - (chance it rains AND rain is predicted)\n",
    "  OR \n",
    "  - (not chance it rain AND not chance predicted its dry))\n",
    "  \n",
    "  P_A * P_BA + not(P_A) * not(P_DRY)\n",
    "\"\"\"\n",
    "P_B = (P_A * P_BA) + (1.0 - P_A) * (1 - P_DRY)\n",
    "\n",
    "P_AB = (P_A * P_BA) / P_B\n",
    "\n",
    "print \"%.2f\" % P_AB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, there is a 48% chance it rains, given the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7\n",
    "\n",
    "A machine is built to make mass-produced items. Each item made by the machine has a probability p of being defective. Given the value of p, the items are independent of each other. Because of the way in which the machines are made, p could take one of several values. In fact p = X/100 where X has a discrete uniform distribution on the interval [0, 5]. The machine is tested by counting the number of items made before a defective is produced. Find the conditional probability distribution of X given that the first defective item is the thirteenth to be made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" cellpadding=\"3\" cellspacing=\"0\"  style=\"border:black; border-collapse:collapse;\"><tr><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">Pr(&nbsp;X&nbsp;=&nbsp;i&nbsp;|&nbsp;D&nbsp;)</td></tr><tr><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.0000</td></tr><tr><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.0915</td></tr><tr><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.1620</td></tr><tr><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.2148</td></tr><tr><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.2529</td></tr><tr><td  style=\"border-left: 1px solid;border-right: 1px solid;border-top: 1px solid;border-bottom: 1px solid;\">0.2788</td></tr></table>"
      ],
      "text/plain": [
       "<ipy_table.ipy_table.IpyTable at 0x10cbc5790>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipy_table import *\n",
    "t = [[\"Pr( X = i | D )\"]]\n",
    "\n",
    "PDX = lambda i: ((1 - i / 100.0) ** (13 - 1)) * (i / 100.0)\n",
    "PX = 1.0 / 6.0\n",
    "r = range(0, 6)\n",
    "# bayes\n",
    "PXiD = lambda i: (PDX(i) * PX) / (sum([(PX * PDX(j)) for j in r]))\n",
    "\n",
    "for i in r:\n",
    "    t.append([PXiD(i)])\n",
    "make_table(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8\n",
    "\n",
    "Calculate the diversity (a.k.a. entropy) associated with the population of strings given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.80\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "M = np.array([\n",
    "    [1, 0, 1, 0, 1, 0, 1],\n",
    "    [0, 1, 0, 1, 0, 1, 0],\n",
    "    [1, 1, 1, 1, 1, 1, 1],\n",
    "    [0, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0, 1]\n",
    "]).T\n",
    "\n",
    "entropies = []\n",
    "for term in M:\n",
    "    m = {0: 0.0, 1: 0.0}\n",
    "    total = len(term)\n",
    "    \n",
    "    Pi = lambda v: (v / total)\n",
    "    expr = lambda v: Pi(m[i]) * np.log2(Pi(m[i]))\n",
    "    \n",
    "    [m.__setitem__(k, (m[k] + 1)) for k in term]\n",
    "    \n",
    "    entropy = sum([expr(i) for i in m])\n",
    "\n",
    "    entropies.append(entropy)\n",
    "\n",
    "joint_entropy = -1 * sum(entropies)\n",
    "\n",
    "print \"%.2f\" % joint_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9\n",
    "\n",
    "Given the following string is representative of the symbol frequency used in a system,\n",
    "and assuming no noise in any communication of those symbols, compute the number of bits that would be needed\n",
    "to send a symbol.\n",
    "\n",
    "`ABCDEACDEADEAE`\n",
    "\n",
    "Assuming 20% noise is associated with any communication, how many bits are now required?\n",
    "HINT: Think of noise as a separate symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy: 2.18\n",
      "requires 31 bits if string is encoded optimally\n",
      "\n",
      "1.0\n",
      "entropy w/ noise: 2.47\n",
      "requires 35 bits if string w/ noise is encoded optimally\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# apparantly did this wrong as well (decrease each terms potency by noise!!)\n",
    "r = 'ABCDEACDEADEAE'\n",
    "l = len(r)\n",
    "\n",
    "m = {}\n",
    "[m.__setitem__(k, (m[k] + 1) if m.has_key(k) else 1.0) for k in r]\n",
    "\n",
    "noise = 0.2\n",
    "\n",
    "total = sum([m[i] for i in m])\n",
    "Pi = lambda v: (v / total)\n",
    "\n",
    "entropy = -1 * sum([Pi(m[i]) * np.log2(Pi(m[i])) for i in m])\n",
    "print \"entropy: %.2f\" % entropy\n",
    "print \"requires %d bits if string is encoded optimally\\n\" % round(entropy * l)\n",
    "\n",
    "# adjust items to account for noise\n",
    "expr = lambda x: (1 - noise) * Pi(m[i]) * np.log2(Pi(m[i]) * (1 - noise))\n",
    "items = [expr(m[i]) for i in m]\n",
    " # add noise as its own symbol\n",
    "items += [noise * np.log2(noise)]\n",
    "\n",
    "i2 = [0.8 * Pi(m[i]) for i in m] + [noise]\n",
    "print sum(i2) # verify sum of probabilities is 1 after noise\n",
    "\n",
    "entropy = -1 * sum(items)\n",
    "\n",
    "print \"entropy w/ noise: %.2f\" % entropy\n",
    "print \"requires %d bits if string w/ noise is encoded optimally\\n\" % round(entropy * l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question 10\n",
    "--------------------\n",
    "Find the KL divergence DL<sub>KL</sub>(P||Q) given `p(x)` = 位<sup>-位x</sup> and `q(x)` = 位<sub>0</sub><sup>-位<sub>0</sub>x</sup>.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    DL_{KL}(P || Q) &= E_{x\\sim{}P}[log(P(x) - log(Q(x)] \\\\\n",
    "    &= E_{x\\sim{}P}[-x(\\lambda{}log(\\lambda{}) - \\lambda{}_0log(\\lambda{}_0))] \\\\\n",
    "    &= \\sum_{x \\in{} X}^{} -P(x)(\\lambda{}log(\\lambda{}) - \\lambda{}_0log(\\lambda{}_0))x \\\\\n",
    "    &= -\\lambda{}log(\\lambda{}) + \\lambda{}_0log(\\lambda{}_0)\\sum_{x \\in{} X}^{} \\frac{x}{\\lambda{}^{\\lambda{}x}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question 11\n",
    "----------------------\n",
    "Find the parameters $(\\mu, \\sigma)$ that minimize the KL divergence of a bimodal gaussian.\n",
    "\n",
    "We define the bimodal gaussian distribution as\n",
    "$$\n",
    "\\begin{align}\n",
    "p(x) &= e^{-\\frac{(x-1)^2}{2 \\times 0.7^2}} + e^{-\\frac{(x-4)^2}{2 \\times 0.7^2}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We also define the approximation distribution in closed form (for solvability) as\n",
    "$$\n",
    "\\begin{align}\n",
    "q(x) &= e^{-\\frac{(x-\\mu)^2}{2 \\times \\sigma^2}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Furthermore, we restrict the domain of the random variable $x \\in X$ to:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "X = \\{0,1,2,3\\}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Note that the question is asking us to solve for $(\\mu, \\sigma)$ of $q(x)$ such that the KL divergence $DL_{KL}(p || q)$ is minimized. It is noted in the Deep Learning Book (www.deeplearningbook.org - Chapter 3 page 73) that minimizing the cross-entropy with respect to $q$ is equivalent to minimizing the KL Divergence. It therefore follows that we need to minimize the following equation:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "H(p,q) &= -\\sum_{x \\in X}{} p(x) \\times log(q(x))\\\\\n",
    "H(p,q) &= -\\sum_{x \\in X}{} (e^{-\\frac{(x-1)^2}{2 \\times 0.7^2}} + e^{-\\frac{(x-4)^2}{2 \\times 0.7^2}})\\times log(e^{-\\frac{(x-\\mu)^2}{2 \\times \\sigma^2}})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Since we are interested in the values of $\\mu$ and $\\sigma$ that minimize $H(p,q)$ defined above, we will need to take two derivatives: one with respect to $\\mu$ and the other with respect to $\\sigma$. Computing these values with Wolfram Alpha, we obtain the following relations:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial}{\\partial \\mu} H(p,q) &= \\sum_{x \\in X}{} \\frac{(e^{-1.02041(-4 + x)^2} + e^{-1.02041(-1 + x)^2})(x-\\mu)}{\\sigma^2}\\\\\n",
    "\\frac{\\partial}{\\partial \\sigma} H(p,q) &= \\sum_{x \\in X}{} \\frac{(e^{-1.02041(-4 + x)^2} + e^{-1.02041(-1 + x)^2})(x-\\mu)^2}{\\sigma^3}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The next step involves applying (pseudo) gradient-descent to the plotted graphs defined above using Wolfram Alpha. The graph of the partial derivative with respect to $\\mu$ is the following:\n",
    "\n",
    "<img src='./mu.png'/>\n",
    "\n",
    "From this we can roughly estimate that the cross entropy is minimized around $\\mu = 1.5$. Finally, the graph of the partial derivative of the cross entropy with respect to $\\sigma$ is the following:\n",
    "\n",
    "<img src='./sigma.png'/>\n",
    "\n",
    "From this we can roughly estimate that the cross entropy is minimized aruond $\\sigma = 0.1$.\n",
    "\n",
    "Therefore, the values $\\sigma = 0.1$ and $\\mu = 1.5$ minimize the KL Divergence of the bimodal Gaussian $p(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
